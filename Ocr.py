import json
import logging
import re
from datetime import datetime
from pathlib import Path
from typing import Any

logger = logging.getLogger("slipscan.ocr")

try:
    from PIL import Image, ImageFilter, ImageEnhance
    PIL_AVAILABLE = True
except ImportError:
    PIL_AVAILABLE = False

try:
    import cv2
    import numpy as np
    CV2_AVAILABLE = True
except ImportError:
    CV2_AVAILABLE = False

try:
    from typhoon_ocr import ocr_document
    TYPHOON_AVAILABLE = True
except ImportError:
    TYPHOON_AVAILABLE = False


# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# IMAGE PREPROCESSOR
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

class ImagePreprocessor:

    @staticmethod
    def preprocess(image_path: str) -> str:
        """‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏†‡∏≤‡∏û ‚Üí ‡∏Ñ‡∏∑‡∏ô path ‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏•‡πâ‡∏ß"""
        if CV2_AVAILABLE:
            return ImagePreprocessor._cv2_preprocess(image_path)
        elif PIL_AVAILABLE:
            return ImagePreprocessor._pil_preprocess(image_path)
        else:
            logger.warning("‡πÑ‡∏°‡πà‡∏°‡∏µ opencv/PIL ‚Äî ‡πÉ‡∏ä‡πâ‡∏†‡∏≤‡∏û‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö")
            return image_path

    @staticmethod
    def _cv2_preprocess(image_path: str) -> str:
        img = cv2.imread(image_path)
        if img is None:
            raise ValueError(f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏†‡∏≤‡∏û: {image_path}")

        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

        # Resize ‡∏ñ‡πâ‡∏≤‡πÄ‡∏•‡πá‡∏Å‡∏Å‡∏ß‡πà‡∏≤ 1200px
        h, w = gray.shape
        if max(h, w) < 1200:
            scale = 1200 / max(h, w)
            gray = cv2.resize(gray, None, fx=scale, fy=scale, interpolation=cv2.INTER_CUBIC)

        # Adaptive Threshold
        thresh = cv2.adaptiveThreshold(
            gray, 255,
            cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
            cv2.THRESH_BINARY, 31, 10
        )

        # Denoise + Sharpen
        denoised = cv2.medianBlur(thresh, 3)
        kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])
        sharp = cv2.filter2D(denoised, -1, kernel)

        out_path = image_path.replace(".", "_processed.")
        cv2.imwrite(out_path, sharp)
        return out_path

    @staticmethod
    def _pil_preprocess(image_path: str) -> str:
        img = Image.open(image_path).convert("L")
        w, h = img.size
        if max(w, h) < 1200:
            scale = 1200 / max(w, h)
            img = img.resize((int(w * scale), int(h * scale)), Image.LANCZOS)
        img = img.filter(ImageFilter.SHARPEN)
        img = ImageEnhance.Contrast(img).enhance(1.5)
        out_path = image_path.replace(".", "_processed.")
        img.save(out_path)
        return out_path


# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# OCR ENGINE
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

class TyphoonOCREngine:


    def __init__(self, base_url: str | None = None, api_key: str | None = None):
        if not TYPHOON_AVAILABLE:
            raise ImportError("pip install typhoon-ocr")
        self.base_url = base_url
        self.api_key  = api_key

    def read(self, image_path: str) -> str:
        """‡∏Ñ‡∏∑‡∏ô raw_text (markdown format)"""
        kwargs = {}
        if self.base_url:
            kwargs["base_url"] = self.base_url
        if self.api_key:
            kwargs["api_key"] = self.api_key

        markdown = ocr_document(pdf_or_image_path=image_path, **kwargs)
        return markdown


# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# SLIP PARSER
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

class SlipParser:


    # ‡∏ò‡∏ô‡∏≤‡∏Ñ‡∏≤‡∏£‡πÑ‡∏ó‡∏¢
    BANK_PATTERNS = {
        '‡∏Å‡∏™‡∏¥‡∏Å‡∏£‡πÑ‡∏ó‡∏¢':     r'(?:kbank|‡∏Å‡∏™‡∏¥‡∏Å‡∏£|kasikorn)',
        '‡πÑ‡∏ó‡∏¢‡∏û‡∏≤‡∏ì‡∏¥‡∏ä‡∏¢‡πå':   r'(?:scb|‡πÑ‡∏ó‡∏¢‡∏û‡∏≤‡∏ì‡∏¥‡∏ä‡∏¢‡πå|siam\s*commercial)',
        '‡∏Å‡∏£‡∏∏‡∏á‡πÑ‡∏ó‡∏¢':      r'(?:ktb|‡∏Å‡∏£‡∏∏‡∏á‡πÑ‡∏ó‡∏¢|krungthai)',
        '‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û':      r'(?:bbl|‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û|bangkok\s*bank)',
        '‡∏ó‡∏´‡∏≤‡∏£‡πÑ‡∏ó‡∏¢‡∏ò‡∏ô‡∏ä‡∏≤‡∏ï': r'(?:ttb|tmb|‡∏ó‡∏´‡∏≤‡∏£‡πÑ‡∏ó‡∏¢|‡∏ò‡∏ô‡∏ä‡∏≤‡∏ï)',
        '‡∏≠‡∏≠‡∏°‡∏™‡∏¥‡∏ô':       r'(?:gsb|‡∏≠‡∏≠‡∏°‡∏™‡∏¥‡∏ô|government\s*savings)',
        '‡∏Å‡∏£‡∏∏‡∏á‡∏®‡∏£‡∏µ':      r'(?:bay|‡∏Å‡∏£‡∏∏‡∏á‡∏®‡∏£‡∏µ|krungsri)',
        '‡∏ò‡∏ô‡∏ä‡∏≤‡∏ï':        r'(?:tbank|‡∏ò‡∏ô‡∏ä‡∏≤‡∏ï|thanachart)',
        '‡∏ã‡∏µ‡πÑ‡∏≠‡πÄ‡∏≠‡πá‡∏°‡∏ö‡∏µ':   r'(?:cimb)',
        '‡∏¢‡∏π‡πÇ‡∏≠‡∏ö‡∏µ':       r'(?:uob)',
    }

    # Regex patterns
    AMOUNT_REGEX = re.compile(
        r'(?:‡∏à‡∏≥‡∏ô‡∏ß‡∏ô|amount|total|‡∏¢‡∏≠‡∏î‡πÇ‡∏≠‡∏ô)[:\s]*([\d,]+\.?\d{0,2})\s*(?:‡∏ö‡∏≤‡∏ó|baht|thb)?',
        re.IGNORECASE
    )
    
    DATE_REGEX = re.compile(
        r'(\d{1,2})\s*(?:‡∏Å\.‡∏û\.|‡∏°\.‡∏Ñ\.|‡∏°‡∏µ\.‡∏Ñ\.|‡πÄ‡∏°\.‡∏¢\.|‡∏û\.‡∏Ñ\.|‡∏°‡∏¥\.‡∏¢\.|‡∏Å\.‡∏Ñ\.|‡∏™\.‡∏Ñ\.|‡∏Å\.‡∏¢\.|‡∏ï\.‡∏Ñ\.|‡∏û\.‡∏¢\.|‡∏ò\.‡∏Ñ\.)\s*(\d{2,4})|(\d{1,2})[\/\-\.](\d{1,2})[\/\-\.](\d{2,4})'
    )
    
    TIME_REGEX = re.compile(
        r'(\d{1,2}):(\d{2})(?::(\d{2}))?\s*(?:‡∏ô\.|AM|PM)?'
    )
    
    REF_REGEX = re.compile(
        r'(?:‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£|ref|‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á|‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏•‡∏Ç|reference)[.\s:]*([A-Z0-9]{10,30})',
        re.IGNORECASE
    )
    
    # ‡∏ö‡∏±‡∏ç‡∏ä‡∏µ‡∏ò‡∏ô‡∏≤‡∏Ñ‡∏≤‡∏£‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ (xxx-x-xxxxx-x)
    BANK_ACCOUNT_REGEX = re.compile(
        r'(xxx[\-]?x[\-]?x\d{4}[\-]?x|\d{3}[\-]?\d{1}[\-]?\d{4,5}[\-]?\d{1})'
    )
    
    # ‡∏£‡∏´‡∏±‡∏™‡∏ú‡∏π‡πâ‡∏£‡∏±‡∏ö/Merchant ID (‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏¢‡∏≤‡∏ß 10-20 ‡∏´‡∏•‡∏±‡∏Å)
    MERCHANT_ID_REGEX = re.compile(
        r'(?<!‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£:\s)(?<!ref\s)(\d{12,20})(?!\s*‡∏ö‡∏≤‡∏ó)',
        re.IGNORECASE
    )

    def parse(self, raw_text: str) -> dict[str, Any]:

        text = raw_text.lower()

        return {
            "sender_name": self._extract_sender_name(raw_text),
            "sender_account": self._extract_sender_account(raw_text),
            "bank_name": self._extract_bank_name(text),
            "amount": self._extract_amount(text),
            "slip_date": self._extract_date(text),
            "slip_time": self._extract_time(text),
            "ref_no": self._extract_ref_no(raw_text),
            "receiver_name": self._extract_receiver_name(raw_text),
            "receiver_account": self._extract_receiver_account(raw_text),
            "raw_ocr": raw_text,
        }

    def _extract_amount(self, text: str) -> float | None:
        # ‡∏•‡∏≠‡∏á‡∏´‡∏≤ pattern ‡∏ó‡∏µ‡πà‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô‡∏Å‡πà‡∏≠‡∏ô
        match = self.AMOUNT_REGEX.search(text)
        if match:
            amount_str = match.group(1).replace(',', '')
            try:
                return float(amount_str)
            except ValueError:
                pass
        
        # Fallback: ‡∏´‡∏≤‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà‡∏°‡∏µ .00 ‡πÅ‡∏•‡∏∞‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡πÄ‡∏•‡∏Ç‡∏¢‡∏≤‡∏ß‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ
        fallback_pattern = re.compile(r'(\d{1,6}\.?\d{0,2})\s*(?:‡∏ö‡∏≤‡∏ó|baht)')
        matches = fallback_pattern.findall(text)
        if matches:
            amounts = []
            for m in matches:
                try:
                    amt = float(m.replace(',', ''))
                    # ‡∏Å‡∏£‡∏≠‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏°‡πÄ‡∏´‡∏ï‡∏∏‡∏™‡∏°‡∏ú‡∏• (0.01 - 999,999.99)
                    if 0.01 <= amt <= 999999.99:
                        amounts.append(amt)
                except ValueError:
                    pass
            # ‡∏Ñ‡∏∑‡∏ô‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡∏°‡∏≤‡∏Å‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î (‡∏°‡∏±‡∏Å‡πÄ‡∏õ‡πá‡∏ô‡∏¢‡∏≠‡∏î‡πÇ‡∏≠‡∏ô‡∏à‡∏£‡∏¥‡∏á)
            return max(amounts) if amounts else None
        
        return None

    def _extract_bank_name(self, text: str) -> str | None:
        for bank, pattern in self.BANK_PATTERNS.items():
            if re.search(pattern, text, re.IGNORECASE):
                return bank
        return None

    def _extract_date(self, text: str) -> str | None:
        # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢
        thai_months = {
            '‡∏°.‡∏Ñ.': 1, '‡∏Å.‡∏û.': 2, '‡∏°‡∏µ.‡∏Ñ.': 3, '‡πÄ‡∏°.‡∏¢.': 4, '‡∏û.‡∏Ñ.': 5, '‡∏°‡∏¥.‡∏¢.': 6,
            '‡∏Å.‡∏Ñ.': 7, '‡∏™.‡∏Ñ.': 8, '‡∏Å.‡∏¢.': 9, '‡∏ï.‡∏Ñ.': 10, '‡∏û.‡∏¢.': 11, '‡∏ò.‡∏Ñ.': 12
        }
        
        # ‡∏•‡∏≠‡∏á pattern ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏Å‡πà‡∏≠‡∏ô (22 ‡∏Å.‡∏û. 69)
        thai_pattern = re.compile(r'(\d{1,2})\s*(‡∏°\.‡∏Ñ\.|‡∏Å\.‡∏û\.|‡∏°‡∏µ\.‡∏Ñ\.|‡πÄ‡∏°\.‡∏¢\.|‡∏û\.‡∏Ñ\.|‡∏°‡∏¥\.‡∏¢\.|‡∏Å\.‡∏Ñ\.|‡∏™\.‡∏Ñ\.|‡∏Å\.‡∏¢\.|‡∏ï\.‡∏Ñ\.|‡∏û\.‡∏¢\.|‡∏ò\.‡∏Ñ\.)\s*(\d{2,4})')
        match = thai_pattern.search(text)
        if match:
            day = int(match.group(1))
            month = thai_months.get(match.group(2))
            year = int(match.group(3))
            
            # ‡πÅ‡∏õ‡∏•‡∏á ‡∏û.‡∏®. ‡πÄ‡∏õ‡πá‡∏ô ‡∏Ñ.‡∏®.
            if year < 100:
                year += 2500  # 69 -> 2569
            if year > 2500:
                year -= 543  # 2569 -> 2026
            
            try:
                return f"{year:04d}-{month:02d}-{day:02d}"
            except (ValueError, TypeError):
                pass
        
        # Fallback: pattern ‡∏õ‡∏Å‡∏ï‡∏¥ (DD/MM/YYYY)
        match = self.DATE_REGEX.search(text)
        if match:
            groups = match.groups()
            # ‡∏ñ‡πâ‡∏≤ match ‡πÅ‡∏ö‡∏ö‡πÑ‡∏ó‡∏¢‡πÅ‡∏•‡πâ‡∏ß groups ‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô (day, month_abbr, year, None, None)
            # ‡∏ñ‡πâ‡∏≤ match ‡πÅ‡∏ö‡∏ö‡∏õ‡∏Å‡∏ï‡∏¥ groups ‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô (None, None, day, month, year)
            if groups[2] and groups[3]:  # ‡πÅ‡∏ö‡∏ö‡∏õ‡∏Å‡∏ï‡∏¥
                day, month, year = int(groups[2]), int(groups[3]), int(groups[4])
                
                # ‡πÅ‡∏õ‡∏•‡∏á ‡∏û.‡∏®. ‡πÄ‡∏õ‡πá‡∏ô ‡∏Ñ.‡∏®.
                if year > 2500:
                    year -= 543
                elif year < 100:
                    year += 2000
                
                try:
                    return f"{year:04d}-{month:02d}-{day:02d}"
                except ValueError:
                    pass
        
        return None

    def _extract_time(self, text: str) -> str | None:
        match = self.TIME_REGEX.search(text)
        if match:
            hour, minute, second = match.groups()
            second = second or "00"
            return f"{int(hour):02d}:{int(minute):02d}:{int(second):02d}"
        return None

    def _extract_ref_no(self, text: str) -> str | None:
        match = self.REF_REGEX.search(text)
        return match.group(1) if match else None

    def _extract_sender_name(self, text: str) -> str | None:
        # ‡∏Å‡∏£‡∏≠‡∏á noise ‡∏≠‡∏≠‡∏Å (‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏£‡∏π‡∏õ, ‡∏Å‡∏≤‡∏£‡πå‡∏ï‡∏π‡∏ô, etc.)
        text_clean = text
        
        # ‡∏•‡∏ö figure tags ‡πÅ‡∏•‡∏∞‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏Ç‡πâ‡∏≤‡∏á‡πÉ‡∏ô
        text_clean = re.sub(r'<figure>.*?</figure>', '', text_clean, flags=re.DOTALL)
        
        # ‡∏•‡∏ö‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô noise
        noise_words = ['one piece', 'ocean of fire', '‡∏¢‡∏∑‡∏ô‡∏≠‡∏¢‡∏π‡πà‡∏ó‡∏≤‡∏á', '‡∏†‡∏≤‡∏û‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö', 'qr code', '‡πÄ‡∏´‡∏£‡∏µ‡∏¢‡∏ç‡∏ó‡∏≠‡∏á', '‡∏ï‡∏±‡∏ß‡∏•‡∏∞‡∏Ñ‡∏£']
        for noise in noise_words:
            text_clean = re.sub(noise, '', text_clean, flags=re.IGNORECASE)
        
        # ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô: ‡∏´‡∏≤‡∏ä‡∏∑‡πà‡∏≠‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡∏´‡∏•‡∏±‡∏á‡∏Ñ‡∏≥‡∏ß‡πà‡∏≤ "‡∏à‡∏≤‡∏Å" ‡∏´‡∏£‡∏∑‡∏≠ "from" ‡∏´‡∏£‡∏∑‡∏≠‡∏ä‡∏∑‡πà‡∏≠‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•‡πÑ‡∏ó‡∏¢
        patterns = [
            r'(?:‡∏à‡∏≤‡∏Å|from)[:\s]+((?:‡∏ô‡∏≤‡∏¢|‡∏ô‡∏≤‡∏á|‡∏ô‡∏≤‡∏á‡∏™‡∏≤‡∏ß|Mr\.|Mrs\.|Ms\.)\s+[\u0E00-\u0E7Fa-zA-Z\s]+)',
            r'(?:‡∏ú‡∏π‡πâ‡πÇ‡∏≠‡∏ô|sender)[:\s]+((?:‡∏ô‡∏≤‡∏¢|‡∏ô‡∏≤‡∏á|‡∏ô‡∏≤‡∏á‡∏™‡∏≤‡∏ß|Mr\.|Mrs\.|Ms\.)\s+[\u0E00-\u0E7Fa-zA-Z\s]+)',
            r'^((?:‡∏ô‡∏≤‡∏¢|‡∏ô‡∏≤‡∏á|‡∏ô‡∏≤‡∏á‡∏™‡∏≤‡∏ß)\s+[\u0E00-\u0E7F]+(?:\s+[\u0E00-\u0E7F]+){1,2})',
        ]
        
        for pattern in patterns:
            match = re.search(pattern, text_clean, re.IGNORECASE | re.MULTILINE)
            if match:
                name = match.group(1).strip()
                # ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î: ‡∏•‡∏ö newlines ‡πÅ‡∏•‡∏∞‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á‡∏ã‡πâ‡∏≥
                name = ' '.join(name.split())
                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà noise
                if len(name) < 100 and not any(n in name.lower() for n in noise_words):
                    return name
        
        return None

    def _extract_receiver_name(self, text: str) -> str | None:
        # ‡∏Å‡∏£‡∏≠‡∏á figure tags
        text_clean = re.sub(r'<figure>.*?</figure>', '', text, flags=re.DOTALL)
        
        patterns = [
            r'(?:‡∏ñ‡∏∂‡∏á|to|‡∏ú‡∏π‡πâ‡∏£‡∏±‡∏ö|receiver)[:\s]+([\u0E00-\u0E7Fa-zA-Z\s&\-\.]+)',
            r'(?:‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó|‡∏´‡πâ‡∏≤‡∏á|‡∏£‡πâ‡∏≤‡∏ô)\s+([\u0E00-\u0E7Fa-zA-Z\s&\-\.]+)',
            # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö K+ format: ‡∏ä‡∏∑‡πà‡∏≠‡∏£‡πâ‡∏≤‡∏ô‡∏≠‡∏¢‡∏π‡πà‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ñ‡∏±‡∏î‡∏à‡∏≤‡∏Å logo/brand
            r'(?:Tops|7-Eleven|Lotus|Big C|Central|Family Mart|Lawson|Makro)\s*(?:daily)?\n?([\u0E00-\u0E7Fa-zA-Z\s&\-\.]+)',
        ]
        
        for pattern in patterns:
            match = re.search(pattern, text_clean, re.IGNORECASE)
            if match:
                name = match.group(1).strip()
                # ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î: ‡∏•‡∏ö newlines ‡πÅ‡∏•‡∏∞‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á‡∏ã‡πâ‡∏≥
                name = ' '.join(name.split())
                # ‡∏Å‡∏£‡∏≠‡∏á‡∏ä‡∏∑‡πà‡∏≠‡∏ó‡∏µ‡πà‡∏™‡∏±‡πâ‡∏ô‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ ‡∏´‡∏£‡∏∑‡∏≠‡∏¢‡∏≤‡∏ß‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ
                if 3 <= len(name) <= 100:
                    return name
        
        return None

    def _extract_sender_account(self, text: str) -> str | None:
        match = self.BANK_ACCOUNT_REGEX.search(text)
        return match.group(1) if match else None

    def _extract_receiver_account(self, text: str) -> str | None:

        # ‡∏•‡∏≠‡∏á‡∏´‡∏≤ merchant ID ‡∏Å‡πà‡∏≠‡∏ô (‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏¢‡∏≤‡∏ß‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà ref no.)
        merchant_match = self.MERCHANT_ID_REGEX.search(text)
        if merchant_match:
            merchant_id = merchant_match.group(1)
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£
            if merchant_id and len(merchant_id) >= 12:
                return merchant_id
        
        # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠ merchant ID ‡πÉ‡∏´‡πâ‡∏´‡∏≤‡∏ö‡∏±‡∏ç‡∏ä‡∏µ‡∏õ‡∏Å‡∏ï‡∏¥ (‡πÅ‡∏ï‡πà‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡∏Ç‡∏≠‡∏á sender)
        # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏£‡∏ì‡∏µ‡πÇ‡∏≠‡∏ô‡πÉ‡∏´‡πâ‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ
        matches = self.BANK_ACCOUNT_REGEX.findall(text)
        if len(matches) > 1:
            # ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏´‡∏•‡∏≤‡∏¢‡∏ö‡∏±‡∏ç‡∏ä‡∏µ ‡πÄ‡∏≠‡∏≤‡∏ï‡∏±‡∏ß‡∏ó‡∏µ‡πà 2 (‡∏ï‡∏±‡∏ß‡πÅ‡∏£‡∏Å‡∏°‡∏±‡∏Å‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡∏≠‡∏á sender)
            return matches[1]
        
        return None

    @staticmethod
    def export_json(data: dict[str, Any], output_path: str, indent: int = 2) -> None:

        path = Path(output_path)
        path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=indent)
        
        logger.info(f"‚úÖ Exported JSON to: {output_path}")

    @staticmethod
    def pretty_print(data: dict[str, Any]) -> None:
        print("\n" + "="*60)
        print("üìÑ SLIP DATA")
        print("="*60)
        for key, value in data.items():
            if key == "raw_ocr":
                print(f"{key:20s}: [‡∏ã‡πà‡∏≠‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô]")
            else:
                print(f"{key:20s}: {value}")
        print("="*60 + "\n")


# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# MAIN
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

class SlipOCR:


    ALLOWED_EXT = {".jpg", ".jpeg", ".png", ".pdf"}

    def __init__(
        self,
        base_url: str | None = None,
        api_key: str | None = None,
        preprocess: bool = True,
        auto_parse: bool = False,
        auto_export: bool = False,
    ):

        self.preprocess = preprocess
        self.auto_parse = auto_parse
        self.auto_export = auto_export
        self._engine = TyphoonOCREngine(base_url=base_url, api_key=api_key)
        self._parser = SlipParser() if auto_parse else None

    def read(
        self,
        image_path: str,
        output_json: str | None = None
    ) -> str | dict[str, Any]:

        path = Path(image_path)
        if not path.exists():
            raise FileNotFoundError(f"‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå: {image_path}")
        if path.suffix.lower() not in self.ALLOWED_EXT:
            raise ValueError(f"‡πÑ‡∏°‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó: {path.suffix}")

        processed = str(path)
        if self.preprocess and path.suffix.lower() != ".pdf":
            try:
                processed = ImagePreprocessor.preprocess(str(path))
            except Exception as e:
                logger.warning(f"Preprocess ‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß: {e} ‚Äî ‡πÉ‡∏ä‡πâ‡∏†‡∏≤‡∏û‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö")

        try:
            raw_text = self._engine.read(processed)
        except Exception as e:
            raise RuntimeError(f"OCR ‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß: {e}") from e

        # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á parse, ‡∏Ñ‡∏∑‡∏ô raw text
        if not self.auto_parse:
            return raw_text

        # Parse ‡πÄ‡∏õ‡πá‡∏ô structured data
        data = self._parser.parse(raw_text)

        # Auto export ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô
        if self.auto_export or output_json:
            json_path = output_json or str(path.with_suffix('.json'))
            self._parser.export_json(data, json_path)

        return data


# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# CLI
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

if __name__ == "__main__":
    import sys

    if len(sys.argv) < 2:
        print("Usage: python Ocr.py <image_path> [options]")
        print("")
        print("Options:")
        print("  --local              ‡πÉ‡∏ä‡πâ self-hosted vllm ‡∏ó‡∏µ‡πà localhost:8000")
        print("  --json               ‡πÅ‡∏õ‡∏•‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÄ‡∏õ‡πá‡∏ô JSON ‡πÅ‡∏•‡∏∞‡πÅ‡∏™‡∏î‡∏á‡∏ö‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠")
        print("  --export <path>      export ‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏ü‡∏•‡πå JSON (default: <image_name>.json)")
        print("")
        print("Examples:")
        print("  python Ocr.py slip.jpg")
        print("  python Ocr.py slip.jpg --json")
        print("  python Ocr.py slip.jpg --json --export output.json")
        print("  python Ocr.py slip.jpg --local --json")
        print("")
        print("Environment:")
        print("  TYPHOON_OCR_API_KEY=your_key   (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö cloud)")
        sys.exit(1)

    image_path = sys.argv[1]
    use_local = "--local" in sys.argv
    use_json = "--json" in sys.argv
    
    # ‡∏î‡∏∂‡∏á path ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö export
    output_json = None
    if "--export" in sys.argv:
        idx = sys.argv.index("--export")
        if idx + 1 < len(sys.argv):
            output_json = sys.argv[idx + 1]
        else:
            print("‚ùå Error: --export requires a file path")
            sys.exit(1)

    base_url = "http://localhost:8000/v1" if use_local else None
    api_key = "no-key" if use_local else None

    # ‡∏™‡∏£‡πâ‡∏≤‡∏á OCR instance
    ocr = SlipOCR(
        base_url=base_url,
        api_key=api_key,
        auto_parse=use_json,
        auto_export=False  # ‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏°‡∏ú‡πà‡∏≤‡∏ô output_json parameter
    )
    
    result = ocr.read(image_path, output_json=output_json)

    if use_json:
        # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡πÅ‡∏ö‡∏ö‡∏™‡∏ß‡∏¢‡∏á‡∏≤‡∏°
        parser = SlipParser()
        parser.pretty_print(result)
        
        # ‡πÅ‡∏™‡∏î‡∏á JSON ‡πÅ‡∏ö‡∏ö compact
        print("JSON Output:")
        print(json.dumps(result, ensure_ascii=False, indent=2))
    else:
        # ‡πÅ‡∏™‡∏î‡∏á raw text
        print(result)